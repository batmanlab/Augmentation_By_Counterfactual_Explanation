{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /jet/home/nmurali/.cache/torch_extensions/py39_cu113 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module upfirdn2d, skipping build step...\n",
      "Loading extension module upfirdn2d...\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, autograd, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from matplotlib.widgets import Slider\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.insert(0,\"/ocean/projects/asc170022p/nmurali/projects/CounterfactualExplainer/MIMICCX-Chest-Explainer/stylegan2Pytorch\")\n",
    "from distributed import (\n",
    "    get_rank,\n",
    "    synchronize,\n",
    "    reduce_loss_dict,\n",
    "    reduce_sum,\n",
    "    get_world_size,\n",
    ")\n",
    "import pdb\n",
    "from op import conv2d_gradfix\n",
    "from non_leaking import augment, AdaptiveAugment\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0,\"/ocean/projects/asc170022p/nmurali/projects/CounterfactualExplainer/MIMICCX-Chest-Explainer/Classifier/torchxrayvision_\")\n",
    "from swagan_updatedEGC import Generator, Discriminator\n",
    "\n",
    "# GUI libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from random import randint\n",
    "\n",
    "sys.path.insert(0,'/jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Classifier')\n",
    "import datasets\n",
    "\n",
    "sys.path.insert(0,\"/ocean/projects/asc170022p/nmurali/projects/CounterfactualExplainer/MIMICCX-Chest-Explainer/Classifier/torchxrayvision_\")\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user hyperparams\n",
    "config_file = '/jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Configs/Classifier/DenseNet_AFHQ.yaml'\n",
    "clf_ckpt_path = '/jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Output/AFHQ/Classifier_Seed_1234_Dropout_0.0_LS_False_MU_False_FL_False_afhq_ln0p38/AFHQ-densenet169-AFHQ_256-best-auc0.5962.pt'\n",
    "gan_ckpt = '/jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Output/StyleGAN/AFHQ_ln0p38/checkpoint/099000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(config_file))\n",
    "config['class_names'] = config['class_names'].split(',')\n",
    "pathologies = config['class_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(pred):\n",
    "    output = ''\n",
    "    for i in range(0, pred.shape[0]):\n",
    "        #if pred[i] > 0.5:\n",
    "        output += pathologies[i] + ': ' + str(pred[i]) + '\\n'\n",
    "    return output\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "class expand_greyscale(object):\n",
    "    def __init__(self):\n",
    "        self.num_target_channels = 3\n",
    "    def __call__(self, tensor):\n",
    "        channels = tensor.shape[0]        \n",
    "        if channels == self.num_target_channels:\n",
    "            return tensor\n",
    "        elif channels == 1:\n",
    "            color = tensor.expand(3, -1, -1)\n",
    "            return color\n",
    "\n",
    "class center_crop(object):\n",
    "    def crop_center(self, img):\n",
    "        _, y, x = img.shape\n",
    "        crop_size = np.min([y,x])\n",
    "        startx = x // 2 - (crop_size // 2)\n",
    "        starty = y // 2 - (crop_size // 2)\n",
    "        return img[:, starty:starty + crop_size, startx:startx + crop_size]\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.crop_center(img)\n",
    "\n",
    "class normalize(object):\n",
    "    def normalize_(self, img, maxval=255):\n",
    "        img = (img)/(maxval)\n",
    "        return img\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return self.normalize_(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['dataset'] == 'AFHQ':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\\\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])), \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    dataset = datasets.AFHQ_Dataset(csvpath=config['data_file'], class_names=config['class_names'], transform=transforms, seed=config['seed'])\n",
    "elif config['dataset'] == 'HAM':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\\\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])), \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = datasets.HAM_Dataset(imgpath=config['imgpath'],csvpath=config['data_file'],class_names=config['class_names'],unique_patients=False, transform=transforms, seed=config['seed'])\n",
    "\n",
    "elif config['dataset'] == 'Dirty_MNIST':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\\\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])), \n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    train_inds = datasets.DIRTY_MNIST_Dataset(csvpath=config['data_file'], transform=transforms, class_names=config['class_names'], seed=config['seed'])\n",
    "    test_inds = datasets.DIRTY_MNIST_Dataset(csvpath=config['data_file_test'], transform=transforms, class_names=config['class_names'], seed=config['seed'])\n",
    "    dataset = None\n",
    "\n",
    "elif config['dataset'] == 'CelebA':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])),\n",
    "        torchvision.transforms.CenterCrop(config['center_crop']),\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = datasets.CelebA(imgpath=config['imgpath'],  csvpath=config['data_file'], class_names=config['class_names'], transform=transforms, seed=config['seed'])\n",
    "\n",
    "elif config['dataset'] == 'Stanford-CHEX':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(center_crop()),\n",
    "        torchvision.transforms.Lambda(normalize())\n",
    "    ])\n",
    "    train_inds = datasets.CheX_Dataset(imgpath=config['imgpath'], csvpath=config['data_file'], class_names=config['class_names'], transform=transforms, seed=config['seed'])\n",
    "    test_inds = datasets.CheX_Dataset(imgpath=config['imgpath'], csvpath=config['data_file_test'], class_names=config['class_names'], transform=transforms, seed=config['seed'])\n",
    "    dataset = None\n",
    "\n",
    "elif config['dataset'] == 'MIMIC-CXR':\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.Resize((config['size'], config['size'])),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Lambda(center_crop()),\n",
    "        torchvision.transforms.Lambda(normalize())\n",
    "    ])\n",
    "    dataset = datasets.MIMIC_Dataset(imgpath=config['imgpath'], csvpath=config['data_file'], class_names=config['class_names'], transform=transforms, seed=config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=15,\n",
    "    #sampler=data.SequentialSampler(dataset),\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_filename_local:  /jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Output/AFHQ/Classifier_Seed_1234_Dropout_0.0_LS_False_MU_False_FL_False_afhq_ln0p38/AFHQ-densenet169-AFHQ_256-best-auc0.5962.pt\n",
      "........\n",
      "model loaded /jet/home/nmurali/asc170022p/nmurali/projects/augmentation_by_explanation_eccv22/Output/AFHQ/Classifier_Seed_1234_Dropout_0.0_LS_False_MU_False_FL_False_afhq_ln0p38/AFHQ-densenet169-AFHQ_256-best-auc0.5962.pt\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "\n",
    "classifier = xrv.models.DenseNet(num_classes=config['num_classes'], in_channels=config['channel'], drop_rate = config['drop_rate'], \\\n",
    "                                 weights = clf_ckpt_path, return_logit=True,\\\n",
    "                                 **xrv.models.get_densenet_params(config['model'])).to(\"cuda\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GAN\n",
    "\n",
    "generator = Generator(config['size'], 512, config['num_classes'], 8, channel_multiplier=2).to(\"cuda\")\n",
    "discriminator = Discriminator(config['size'], channel_multiplier=2, concate_size=0).to(\"cuda\")\n",
    "\n",
    "gan_ckpt = torch.load(gan_ckpt, map_location=lambda storage, loc: storage)\n",
    "generator.load_state_dict(gan_ckpt[\"g\"])\n",
    "discriminator.load_state_dict(gan_ckpt[\"d\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widget functions (for event handling)\n",
    "\n",
    "def stylegan(img_id, attr1, val1):\n",
    "    \n",
    "    requires_grad(generator, False)\n",
    "    requires_grad(discriminator, False)\n",
    "    requires_grad(classifier, False)\n",
    "\n",
    "    real_img = dataset[int(img_id)]['img'].unsqueeze(0)\n",
    "    real_img = real_img.to(\"cuda\")\n",
    "    real_pred_cls, clf_feats_real = classifier(real_img)\n",
    "    real_pred_cls = torch.sigmoid(real_pred_cls) \n",
    "    real_d = discriminator(real_img, clf_feats_real)\n",
    "    real_d = torch.sigmoid(real_d)\n",
    "\n",
    "    real_img1 = np.asarray(real_img.detach().cpu())\n",
    "    real_img1 = np.moveaxis(real_img1, 1, 3)\n",
    "    real_pred_cls1 = np.round(np.asarray(real_pred_cls.detach().cpu()),4)\n",
    "    real_d = np.round(np.asarray(real_d.detach().cpu()),4)\n",
    "    attr_idx = pathologies.index(attr1)\n",
    "\n",
    "    # first plot\n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    plt.subplot(1,2,1)\n",
    "    img = real_img1[0]\n",
    "    plt.imshow((img-img.min())/(img.max()-img.min()))\n",
    "    plt.title('clf:%.2f, D:%.2f' %(real_pred_cls1[0][attr_idx],real_d[0][0]), fontsize=20)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylabel(real_d[0][0])\n",
    "    \n",
    "    # create input vec (condition) for gan\n",
    "    vec = real_pred_cls1[0]\n",
    "    vec[attr_idx] = val1\n",
    "    vec = np.repeat(np.expand_dims(vec,0),1,axis=0)\n",
    "    vec = torch.Tensor(vec)\n",
    "    vec = vec.to(\"cuda\")\n",
    "\n",
    "    recon_img, real_img_latent = generator(real_img, vec, return_latents=True)\n",
    "    _, recon_img_latent = generator(recon_img, vec, return_latents=True)\n",
    "    \n",
    "    # calculate cosine similarity between latent vectors\n",
    "    real_img_latent = torch.flatten(real_img_latent)\n",
    "    recon_img_latent = torch.flatten(recon_img_latent)\n",
    "    cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "    cos_sim = cos(real_img_latent, recon_img_latent)\n",
    "    \n",
    "    \n",
    "    recon_pred_cls, clf_feats_recon = classifier(recon_img)\n",
    "    recon_pred_cls = torch.sigmoid(recon_pred_cls)\n",
    "    fake_d = discriminator(recon_img, clf_feats_recon)\n",
    "    fake_d = torch.sigmoid(fake_d)\n",
    "    \n",
    "    recon_img1 = np.asarray(recon_img.detach().cpu())\n",
    "    recon_img1 = np.moveaxis(recon_img1, 1, 3)\n",
    "    recon_pred_cls1 = np.round(np.asarray(recon_pred_cls.detach().cpu()), 4)\n",
    "    fake_d = np.round(np.asarray(fake_d.detach().cpu()),4)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    img = recon_img1[0]\n",
    "    plt.imshow((img-img.min())/(img.max()-img.min()))\n",
    "    plt.title('clf:%.2f, D:%.2f, Cos Sim:%f' %(recon_pred_cls1[0][attr_idx],fake_d[0][0],cos_sim), fontsize=20)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylabel(fake_d[0][0])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def change_img(btn):\n",
    "    text_box.value = str(randint(0,len(dataset)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# widgets\n",
    "menu1 = widgets.Dropdown(\n",
    "    options=config['class_names'],\n",
    "    value='cat',\n",
    "    description='Attribute-1',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "slider1 = widgets.FloatSlider(value=0.0,\n",
    "                              min=0,\n",
    "                              max=1,\n",
    "                              step=0.1,\n",
    "                              description='Attribute-1',\n",
    "                              disabled=False,\n",
    "                              continuous_update=False,\n",
    "                              orientation='horizontal',\n",
    "                              readout=True,\n",
    "                              readout_format='0.2f',\n",
    "                              msg_throttle=1)\n",
    "\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Change Image',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click me',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "text_box = widgets.Text(\n",
    "    value='0',\n",
    "    placeholder='',\n",
    "    description='Image ID',\n",
    "    disabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ca3162258648e6ac2023e90ec2eab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='0', description='Image ID', disabled=True, placeholder=''), Dropdown(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b921e5bbfb624f988871bdd2dd7c34cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Change Image', icon='check', style=ButtonStyle(), tooltip='Click me')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive GUI\n",
    "\n",
    "widgets.interact(stylegan, img_id=text_box, attr1=menu1, val1=slider1);\n",
    "display(button)\n",
    "button.on_click(change_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requires_grad(generator, False)\n",
    "requires_grad(discriminator, False)\n",
    "requires_grad(classifier, False)\n",
    "\n",
    "current_class = 1 # 1:Cardiomegaly, 4:Edema, 9:Pleural Effusion\n",
    "img_id = 7268\n",
    "\n",
    "real_img = np.asarray(dataset[int(img_id)]['img'].unsqueeze(0).detach().cpu())\n",
    "real_img = np.repeat(real_img, 100,axis=0)\n",
    "real_img = torch.from_numpy(real_img)\n",
    "real_img = real_img.to(\"cuda\")\n",
    "\n",
    "real_pred_cls, _ = classifier(real_img)\n",
    "real_pred_cls = torch.sigmoid(real_pred_cls) \n",
    "\n",
    "cond = np.asarray([0.01 * i for i in range(100)])\n",
    "real_pred_cls_npy = np.asarray(real_pred_cls.detach().cpu())\n",
    "real_pred_cls_npy[:,current_class] = cond\n",
    "current_cond  = torch.from_numpy(real_pred_cls_npy)\n",
    "current_cond = current_cond.to(\"cuda\")\n",
    "\n",
    "recon_img, _ = generator(real_img, current_cond, return_latents=False)\n",
    "recon_pred_cls, _ = classifier(recon_img)\n",
    "recon_pred_cls = torch.sigmoid(recon_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "n = batch_size\n",
    "cond = np.asarray([0.1 * i for i in range(10)])\n",
    "cond = np.repeat(cond,n,axis=0)\n",
    "cond = np.reshape(cond, [10,n])\n",
    "cond = np.transpose(cond)\n",
    "cond = np.ravel(cond)\n",
    "cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred_cls_npy[:,current_class].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for celeba\n",
    "requires_grad(generator, False)\n",
    "requires_grad(discriminator, False)\n",
    "requires_grad(classifier, False)\n",
    "all_real_pred = np.empty([0])\n",
    "all_fake_pred = np.empty([0])\n",
    "all_cond = np.empty([0])\n",
    "current_class = 1 # 1:Cardiomegaly, 4:Edema, 9:Pleural Effusion\n",
    "counter = 0\n",
    "for batch in tqdm(loader):\n",
    "    real_img = np.asarray(batch['img'].detach().cpu())\n",
    "    real_img = np.repeat(real_img, 10,axis=0)\n",
    "    real_img = torch.from_numpy(real_img)\n",
    "    real_img = real_img.to(\"cuda\")\n",
    "    real_pred_cls, _ = classifier(real_img)\n",
    "    real_pred_cls = torch.sigmoid(real_pred_cls) \n",
    "    real_pred_cls_npy = np.asarray(real_pred_cls.detach().cpu())\n",
    "    real_pred_cls_npy[:,current_class] = cond\n",
    "    current_cond  = torch.from_numpy(real_pred_cls_npy)\n",
    "    current_cond = current_cond.to(\"cuda\")\n",
    "    recon_img, _ = generator(real_img, current_cond, return_latents=False)\n",
    "    recon_pred_cls, _ = classifier(recon_img)\n",
    "    recon_pred_cls = torch.sigmoid(recon_pred_cls)\n",
    "    if all_real_pred.shape[0] == 0:\n",
    "        all_real_pred = np.asarray(real_pred_cls.detach().cpu())\n",
    "        all_cond = np.asarray(current_cond.detach().cpu())\n",
    "        all_fake_pred = np.asarray(recon_pred_cls.detach().cpu())\n",
    "    else:\n",
    "        all_real_pred = np.append(all_real_pred, np.asarray(real_pred_cls.detach().cpu()),axis=0)\n",
    "        all_fake_pred = np.append(all_fake_pred,np.asarray(recon_pred_cls.detach().cpu()) ,axis=0)\n",
    "        all_cond = np.append(all_cond,  np.asarray(current_cond.detach().cpu()),axis=0)\n",
    "    counter += 1\n",
    "    if counter == 15:\n",
    "        break\n",
    "print(all_real_pred.shape, all_cond.shape, all_fake_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred_cls[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pred2 = all_real_pred\n",
    "all_cond2 = all_cond\n",
    "all_fake_pred2 = all_fake_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pred = np.reshape(all_real_pred, [-1,10,6])\n",
    "all_cond = np.reshape(all_cond, [-1,10,6])\n",
    "all_fake_pred = np.reshape(all_fake_pred, [-1,10,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pred = np.mean(all_real_pred, axis=1)\n",
    "all_real_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fake_pred = np.reshape(all_fake_pred, [-1,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cond = np.reshape(all_cond, [-1,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_real_pred.shape, all_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [current_class]:\n",
    "    print(\"Current Class: \", c)\n",
    "    bins =  np.asarray(all_real_pred[:,c]*10).astype(int)\n",
    "    print(np.unique(bins,return_counts=True))\n",
    "\n",
    "    target_bin = np.asarray(all_cond[:,c]*10).astype(int)\n",
    "    source_bin = np.repeat(bins, repeats=10)\n",
    "    source_pred = np.repeat(all_real_pred[:,c], repeats=10)\n",
    "    target_pred = all_fake_pred[:,c]\n",
    "    delta = target_bin-source_bin\n",
    "    print(target_bin.shape, source_bin.shape, source_pred.shape,target_pred.shape,delta.shape)\n",
    "    print(np.min(delta), np.max(delta))\n",
    "\n",
    "    real_p = target_bin * 0.1\n",
    "    real_p_ = (target_bin+1) * 0.1\n",
    "    real_p = (real_p + real_p_)/2\n",
    "    fake_q = target_pred\n",
    "    \n",
    "    from matplotlib import cm\n",
    "    colors = cm.get_cmap('viridis', 5)\n",
    "    newcolors = colors(np.linspace(0, 1, 5))\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"white\")\n",
    "    sns.set_context(\"notebook\", font_scale=2.5, rc={\"lines.linewidth\": 2})\n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    names = ['0.0-0.2', '', '0.2-0.4', '0.30-0.40', '0.4-0.6', '0.50-0.60', \\\n",
    "             '0.6-0.8', '0.70-0.80', '0.8-1.0', '0.90-1.00']\n",
    "    makrker_size = [10,0,9,0,13,0,13,0,13,0]\n",
    "    markers = ['o', '','s','','*', '','X', 'X', '<', '>', 's', '*', 'D', 'd', 'X']\n",
    "    x = np.arange(0.0, 1.0, step=0.1)\n",
    "    plt.plot(x, x,c='black',linestyle='dashed',alpha=0.5) # dashdot black\n",
    "    for i in range(0,10,2):\n",
    "        index = np.where(source_bin == i)\n",
    "        print(index[0].shape,i)\n",
    "        target_pred_i = fake_q[index]\n",
    "        source_pred_i = real_p[index]\n",
    "        index = np.where(source_bin == i+1)\n",
    "        target_pred_i = np.append(target_pred_i, fake_q[index],axis=0)\n",
    "        source_pred_i = np.append(source_pred_i,real_p[index],axis=0)\n",
    "        target_pred_i = np.reshape(target_pred_i,[-1,10])\n",
    "        source_pred_i = np.reshape(source_pred_i,[-1,10])\n",
    "        \n",
    "        \n",
    "        mean_t = np.mean(target_pred_i,0)\n",
    "        sd_t = np.std(target_pred_i,0)           \n",
    "        mean_s = np.mean(source_pred_i,0)\n",
    "        sd_s = np.std(source_pred_i,0)\n",
    "        x_axis = np.arange(0.0, 1.0, step=0.1)\n",
    "        ax = sns.lineplot(mean_s,mean_t,label=names[i],color=newcolors[int(i/2)],\\\n",
    "                              alpha=1,marker=markers[i], markersize=makrker_size[i])\n",
    "    plt.xticks(np.arange(0, 1.1, step=0.2))\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.2))\n",
    "    ax.get_legend().remove()\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    #plt.legend(loc=2)\n",
    "    plt.xlabel( r'$f(x)+\\delta$' )\n",
    "    plt.ylabel(r'$f(x_{\\delta})$')\n",
    "    plt.title(pathologies[c])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/jet/home/nmurali/asc170022p/nmurali/data/mimic/uniform_mimic_clf_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array(df['cardiomegaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = AnyDataset(csv_path='/jet/home/nmurali/asc170022p/nmurali/data/mimic/uniform_mimic_clf_preds.csv',pathologies='Cardiomegaly')\n",
    "# store = Store()\n",
    "# for bidx,batch in enumerate(tqdm(data)):\n",
    "#     img = batch['x']\n",
    "#     img=torch.tensor(img).unsqueeze(0).to(\"cuda\")\n",
    "#     preds, _ = classifier(img)\n",
    "#     preds = torch.sigmoid(preds)\n",
    "#     store.feed([preds[0][1].unsqueeze(0)])\n",
    "#     if bidx==100:\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.array((store.lov[0]).cpu().detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2 = AnyDataset(csv_path='/ocean/projects/asc170022p/nmurali/data/mimic/all.csv',img_path_field='lateral_512_jpeg',pathologies='Cardiomegaly',transform='mimic')\n",
    "# img = data2[200000]['x']\n",
    "# img=torch.tensor(img).unsqueeze(0).to(\"cuda\")\n",
    "# preds, _ = classifier(img)\n",
    "# preds = torch.sigmoid(preds)\n",
    "# print(preds[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/ocean/projects/asc170022p/nmurali/data/mimic/all.csv')\n",
    "# np.unique(np.array(df['Cardiomegaly'].values.tolist()),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/jet/home/nmurali/asc170022p/nmurali/projects/misc/Pytorch-UNet/mimic_clf_preds.csv')\n",
    "# np.unique(np.array((df['cardiomegaly']>0.8).values.tolist()),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "mimic_csv_path = '/ocean/projects/asc170022p/nmurali/data/mimic/all.csv'\n",
    "dataset = AnyDataset(csv_path=mimic_csv_path, img_path_field='lateral_512_jpeg', transform='mimic')\n",
    "\n",
    "pathologies = ['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Lesion', 'Lung Opacity', 'Edema', 'Consolidation',\n",
    "                'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture']\n",
    "\n",
    "# dataloader\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    #sampler=data.SequentialSampler(dataset),\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = Store()\n",
    "for bidx, batch in enumerate(tqdm(loader)):\n",
    "    with torch.no_grad():\n",
    "        img = batch['x']\n",
    "        img=torch.tensor(img).to(\"cuda\")\n",
    "        preds, _ = classifier(img)\n",
    "        preds = torch.sigmoid(preds)\n",
    "        store.feed([batch['path'],preds[:,1],preds[:,4],preds[:,9]])\n",
    "        if bidx==3000:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array((store.lov[1]).cpu().detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = get_df(store.lov,cols=['path','cardiomegaly','edema','pleural_effusion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./final_mimic_uniform.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique((final_df['cardiomegaly']>0.7),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list= []\n",
    "df1 = final_df\n",
    "df_list.append(df1[df1['cardiomegaly']<0.2].sample(1000))\n",
    "df_list.append(df1[(df1['cardiomegaly']>0.2) & (df1['cardiomegaly']<0.4)].sample(1000))\n",
    "df_list.append(df1[(df1['cardiomegaly']>0.4) & (df1['cardiomegaly']<0.5)].sample(1000))\n",
    "df_list.append(df1[(df1['cardiomegaly']>0.5) & (df1['cardiomegaly']<0.7)].sample(2000))\n",
    "df_list.append(df1[(df1['cardiomegaly']>0.7)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardio = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = final_df\n",
    "# df1[(df1['cardiomegaly']>0.000001) & (df1['cardiomegaly']<0.1)]\n",
    "df_cardio = df_cardio.sample(6136)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardio.to_csv('./final_mimic_uniform_sampled.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_cardio['cardiomegaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a88dc7f5182e5da1801d8474c85899bd75b375bf8cebc59e548b2bda58bdd0aa"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
